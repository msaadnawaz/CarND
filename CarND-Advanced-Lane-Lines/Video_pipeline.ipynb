{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def undistort(img):\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return dst\n",
    "\n",
    "def hls_transform(img, thresh):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    sat = hls[:,:,2]\n",
    "    binary = np.zeros_like(sat)\n",
    "    binary[(sat > thresh[0]) & (sat <= thresh[1])] = 1\n",
    "    return binary\n",
    "\n",
    "def abs_grad(img, sobel_kernel, thresh, orient):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, sobel_kernel))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, sobel_kernel))\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    binary = np.zeros_like(scaled_sobel)\n",
    "    binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return binary\n",
    "\n",
    "def mag_grad(img, sobel_kernel, thresh):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8)\n",
    "    binary = np.zeros_like(gradmag)\n",
    "    binary[(gradmag >= thresh[0]) & (gradmag <= thresh[1])] = 1\n",
    "    return binary\n",
    "\n",
    "def dir_grad(img, sobel_kernel, thresh):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    graddir = np.arctan2(np.absolute(sobely),np.absolute(sobelx))\n",
    "    binary = np.zeros_like(graddir)\n",
    "    binary[(graddir >= thresh[0]) & (graddir <= thresh[1])] = 1\n",
    "    return binary\n",
    "\n",
    "def combined_gradient(img, ksize):\n",
    "    gradx = abs_grad(img, sobel_kernel=ksize, thresh=(100, 255), orient='x')\n",
    "    grady = abs_grad(img, sobel_kernel=ksize, thresh=(100, 255), orient='y')\n",
    "    mag_binary = mag_grad(img, sobel_kernel=ksize, thresh=(100, 255))\n",
    "    dir_binary = dir_grad(img, sobel_kernel=ksize, thresh=(np.pi/4, np.pi/2))\n",
    "    \n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    return combined\n",
    "\n",
    "def pers_trans(img, src, dst):\n",
    "    #gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(img, M, img_size)\n",
    "    return warped\n",
    "\n",
    "def histo(img):\n",
    "    histogram = np.sum(img[img.shape[0]//2:,:], axis=0)\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "camera_calibration_values = open('cal_coeff.p', 'rb') \n",
    "camera_calibration_values = pickle.load(camera_calibration_values)\n",
    "mtx = camera_calibration_values['mtx'] \n",
    "dist = camera_calibration_values['dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lane_finder(img):\n",
    "    #[mtx, dist] = pickle.load( open( \"cal_coeff.p\", \"rb\" ) )\n",
    "    \n",
    "    undist = img\n",
    "    \n",
    "    hls = hls_transform(undist, (100,255))\n",
    "    grad = combined_gradient(undist, 3)\n",
    "    \n",
    "    mixed = np.zeros_like(grad)\n",
    "    mixed[(grad == 1) | (hls == 1)] = 1\n",
    "    \n",
    "    img_size = (undist.shape[1], undist.shape[0])\n",
    "\n",
    "    src = np.float32([[np.int(img_size[0]*0.435), np.int(img_size[1]*0.65)],\n",
    "                      [np.int(img_size[0]*0.565), np.int(img_size[1]*0.65)],\n",
    "                      [np.int(img_size[0]*0.9), img_size[1]],\n",
    "                      [np.int(img_size[0]*0.1), img_size[1]]])\n",
    "    offset = 150\n",
    "\n",
    "    dst = np.float32([[offset, 0], \n",
    "                      [img_size[0]-offset, offset], \n",
    "                      [img_size[0]-offset, img_size[1]], \n",
    "                      [offset, img_size[1]]])\n",
    "    \n",
    "    warped = pers_trans(mixed,src,dst)\n",
    "    histogram = histo(warped)\n",
    "    \n",
    "    \n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((warped, warped, warped))*255\n",
    "\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(warped.shape[0]/nwindows)\n",
    "\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    if Left_Line.recent_xfitted:\n",
    "        leftx_current = Left_Line.recent_xfitted[-1][-1]\n",
    "    else:\n",
    "        leftx_current = leftx_base\n",
    "    \n",
    "    if Right_Line.recent_xfitted:\n",
    "        rightx_current = Right_Line.recent_xfitted[-1][-1]\n",
    "    else:\n",
    "        rightx_current = rightx_base\n",
    "    \n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "\n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    \n",
    "    # Extract left and right line pixel positions\n",
    "    if len(left_lane_inds):\n",
    "        Left_Line.allx = nonzerox[left_lane_inds]\n",
    "        Left_Line.ally = nonzeroy[left_lane_inds]\n",
    "        Left_Line.detected = True\n",
    "    \n",
    "    if len(right_lane_inds):\n",
    "        Right_Line.allx = nonzerox[right_lane_inds]\n",
    "        Right_Line.ally = nonzeroy[right_lane_inds]\n",
    "        Right_Line.detected = True\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    Left_Line.current_fit = np.polyfit(Left_Line.ally, Left_Line.allx, 2)\n",
    "    Right_Line.current_fit = np.polyfit(Right_Line.ally, Right_Line.allx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0] )\n",
    "    left_fitx = Left_Line.current_fit[0]*ploty**2 + Left_Line.current_fit[1]*ploty + Left_Line.current_fit[2]\n",
    "    right_fitx = Right_Line.current_fit[0]*ploty**2 + Right_Line.current_fit[1]*ploty + Right_Line.current_fit[2]\n",
    "    \n",
    "    if Left_Line.detected:\n",
    "        if len(Left_Line.recent_xfitted)>10:\n",
    "            Left_Line.recent_xfitted.pop(0)\n",
    "        Left_Line.recent_xfitted.append(left_fitx)\n",
    "    \n",
    "    if Right_Line.detected:\n",
    "        if len(Right_Line.recent_xfitted)>10:\n",
    "            Right_Line.recent_xfitted.pop(0)\n",
    "        Right_Line.recent_xfitted.append(right_fitx)\n",
    "    \n",
    "    Left_Line.bestx = sum(Left_Line.recent_xfitted)/len(Left_Line.recent_xfitted)\n",
    "    Right_Line.bestx = sum(Right_Line.recent_xfitted)/len(Right_Line.recent_xfitted)\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    y_eval = np.max(ploty)\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    #position from center\n",
    "    lane_center = 640\n",
    "    right_distance = right_fitx[-1]-lane_center\n",
    "    left_distance = lane_center - left_fitx[-1]\n",
    "    \n",
    "    if Left_Line.line_base_pos:\n",
    "        if np.absolute(right_distance - left_distance) < 100:\n",
    "            Right_Line.line_base_pos = right_distance\n",
    "            Left_Line.line_base_pos = left_distance\n",
    "    else:\n",
    "        Right_Line.line_base_pos = right_distance\n",
    "        Left_Line.line_base_pos = left_distance\n",
    "    \n",
    "    pos_from_center = np.absolute(Right_Line.line_base_pos - Left_Line.line_base_pos)*xm_per_pix\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(Left_Line.ally*ym_per_pix, Left_Line.allx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(Right_Line.ally*ym_per_pix, Right_Line.allx*xm_per_pix, 2)\n",
    "\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    if Left_Line.radius_of_curvature:\n",
    "        if np.absolute(Left_Line.radius_of_curvature - left_curverad) < 400:\n",
    "            Left_Line.radius_of_curvature = left_curverad\n",
    "    else:\n",
    "        Left_Line.radius_of_curvature = left_curverad\n",
    "        \n",
    "    if Right_Line.radius_of_curvature:\n",
    "        if np.absolute(Right_Line.radius_of_curvature - right_curverad) < 400:\n",
    "            Right_Line.radius_of_curvature = right_curverad\n",
    "    else:\n",
    "        Right_Line.radius_of_curvature = right_curverad\n",
    "        \n",
    "    pts_left = np.array([np.transpose(np.vstack([Left_Line.bestx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([Right_Line.bestx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    fitted_lane_image = np.zeros_like(warped)\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(fitted_lane_image, np.int_([pts]), 1)\n",
    "\n",
    "    unwarp = pers_trans(fitted_lane_image, dst, src)\n",
    "    lanes=np.zeros_like(undist)\n",
    "    lanes[(unwarp>0)]=(0,255,0)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    overlayed = cv2.addWeighted(undist, 1, lanes, 0.3, 0)\n",
    "\n",
    "    left_text = 'Left lane curvature: %dm' %Left_Line.radius_of_curvature\n",
    "    right_text = 'Right lane curvature: %dm' %Right_Line.radius_of_curvature\n",
    "    pos_text = 'Position from lane center: %.3fm'%pos_from_center\n",
    "    cv2.putText(overlayed, left_text, (np.int(overlayed.shape[1]*0.55),np.int(overlayed.shape[0]*0.05)), font, 1, (0,255,0), 4, cv2.LINE_AA)\n",
    "    cv2.putText(overlayed, right_text, (np.int(overlayed.shape[1]*0.55),np.int(overlayed.shape[0]*0.1)), font, 1, (0,255,0), 4, cv2.LINE_AA)\n",
    "    cv2.putText(overlayed, pos_text, (np.int(overlayed.shape[1]*0.55),np.int(overlayed.shape[0]*0.15)), font, 1, (0,255,0), 4, cv2.LINE_AA)\n",
    "\n",
    "    return overlayed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_output.mp4\n",
      "[MoviePy] Writing video project_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████▉| 1260/1261 [04:21<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output.mp4 \n",
      "\n",
      "Wall time: 4min 22s\n"
     ]
    }
   ],
   "source": [
    "output = 'project_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "\n",
    "Left_Line = Line()\n",
    "Right_Line = Line()\n",
    "\n",
    "road_clip = clip1.fl_image(lane_finder) #NOTE: this function expects color images!!\n",
    "%time road_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video challenge_video_output.mp4\n",
      "[MoviePy] Writing video challenge_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 485/485 [01:33<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: challenge_video_output.mp4 \n",
      "\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "challenge_output = 'challenge_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "\n",
    "Left_Line = Line()\n",
    "Right_Line = Line()\n",
    "\n",
    "road_clip = clip1.fl_image(lane_finder) #NOTE: this function expects color images!!\n",
    "%time road_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video harder_challenge_video_output.mp4\n",
      "[MoviePy] Writing video harder_challenge_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████▉| 1199/1200 [04:15<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: harder_challenge_video_output.mp4 \n",
      "\n",
      "Wall time: 4min 15s\n"
     ]
    }
   ],
   "source": [
    "harder_challenge_output = 'harder_challenge_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "\n",
    "Left_Line = Line()\n",
    "Right_Line = Line()\n",
    "\n",
    "road_clip = clip1.fl_image(lane_finder) #NOTE: this function expects color images!!\n",
    "%time road_clip.write_videofile(harder_challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
